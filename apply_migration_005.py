#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ 005: Performance Optimization –¥–ª—è 200 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –±—ç–∫–∞–ø–æ–º
- –ü—Ä–æ–≤–µ—Ä–∫–æ–π –ø–µ—Ä–µ–¥/–ø–æ—Å–ª–µ
- Rollback –ø—Ä–∏ –æ—à–∏–±–∫–µ
- –ü–æ–¥—Ä–æ–±–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
"""

import sqlite3
import os
import shutil
from datetime import datetime
from pathlib import Path

# –ü—É—Ç–∏
DB_PATH = Path('local_backup.db')
MIGRATION_FILE = Path('migrations/005_performance_optimization.sql')
BACKUP_DIR = Path('backups')

def create_backup():
    """–°–æ–∑–¥–∞–µ—Ç –±—ç–∫–∞–ø –ë–î –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π"""
    print("üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞...")
    
    BACKUP_DIR.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_path = BACKUP_DIR / f'local_backup_{timestamp}_before_migration_005.db'
    
    shutil.copy2(DB_PATH, backup_path)
    print(f"‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_path}")
    print(f"   –†–∞–∑–º–µ—Ä: {backup_path.stat().st_size / 1024:.1f} KB")
    return backup_path

def get_db_stats(conn):
    """–°–æ–±–∏—Ä–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ë–î"""
    stats = {}
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
    stats['logs_count'] = conn.execute("SELECT COUNT(*) FROM logs").fetchone()[0]
    stats['sessions_count'] = conn.execute("SELECT COUNT(*) FROM sessions").fetchone()[0]
    
    # Pending sync
    stats['pending_sync'] = conn.execute("SELECT COUNT(*) FROM logs WHERE synced = 0").fetchone()[0]
    
    # –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏
    stats['active_sessions'] = conn.execute(
        "SELECT COUNT(*) FROM sessions WHERE logout_time IS NULL"
    ).fetchone()[0]
    
    # –†–∞–∑–º–µ—Ä –ë–î
    stats['db_size_kb'] = DB_PATH.stat().st_size / 1024
    
    # –ò–Ω–¥–µ–∫—Å—ã
    indexes = conn.execute(
        "SELECT COUNT(*) FROM sqlite_master WHERE type='index' AND tbl_name IN ('logs', 'sessions')"
    ).fetchone()[0]
    stats['indexes_count'] = indexes
    
    # Journal mode
    journal_mode = conn.execute("PRAGMA journal_mode").fetchone()[0]
    stats['journal_mode'] = journal_mode
    
    return stats

def print_stats(stats, title="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ë–î"):
    """–ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    print(f"\n{'='*60}")
    print(f"{title:^60}")
    print(f"{'='*60}")
    print(f"  –ó–∞–ø–∏—Å–µ–π –≤ logs:        {stats['logs_count']:,}")
    print(f"  –ó–∞–ø–∏—Å–µ–π –≤ sessions:    {stats['sessions_count']:,}")
    print(f"  Pending sync:          {stats['pending_sync']:,}")
    print(f"  –ê–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π:       {stats['active_sessions']:,}")
    print(f"  –ò–Ω–¥–µ–∫—Å–æ–≤:              {stats['indexes_count']}")
    print(f"  Journal mode:          {stats['journal_mode']}")
    print(f"  –†–∞–∑–º–µ—Ä –ë–î:             {stats['db_size_kb']:.1f} KB")
    print(f"{'='*60}\n")

def check_migration_applied(conn):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –ª–∏ —É–∂–µ –º–∏–≥—Ä–∞—Ü–∏—è"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–¥–Ω–æ–≥–æ –∏–∑ –Ω–æ–≤—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
        result = conn.execute("""
            SELECT name FROM sqlite_master 
            WHERE type='index' AND name='idx_logs_email_timestamp'
        """).fetchone()
        return result is not None
    except:
        return False

def apply_migration(conn):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–∏–≥—Ä–∞—Ü–∏—é –∏–∑ SQL —Ñ–∞–π–ª–∞"""
    print("üîß –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏ 005...")
    
    # –ß–∏—Ç–∞–µ–º SQL
    with open(MIGRATION_FILE, 'r', encoding='utf-8') as f:
        sql = f.read()
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã (–ø–æ PRAGMA –∏ CREATE)
    statements = []
    current = []
    
    for line in sql.split('\n'):
        line = line.strip()
        if not line or line.startswith('--'):
            continue
        
        current.append(line)
        
        # –ö–æ–Ω–µ—Ü –∫–æ–º–∞–Ω–¥—ã
        if line.endswith(';'):
            statements.append(' '.join(current))
            current = []
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–µ
    executed = 0
    for statement in statements:
        if statement.strip():
            try:
                conn.execute(statement)
                executed += 1
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è CREATE INDEX
                if 'CREATE INDEX' in statement:
                    index_name = statement.split('IF NOT EXISTS')[1].split('ON')[0].strip()
                    print(f"   ‚úì –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å: {index_name}")
            except Exception as e:
                print(f"   ‚ö† –ü—Ä–æ–ø—É—â–µ–Ω–æ: {str(e)[:50]}...")
    
    conn.commit()
    print(f"‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ {executed} –∫–æ–º–∞–Ω–¥")

def verify_migration(conn):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –º–∏–≥—Ä–∞—Ü–∏–∏"""
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏...")
    
    checks = {
        'WAL mode': lambda: conn.execute("PRAGMA journal_mode").fetchone()[0] == 'wal',
        'idx_logs_email_timestamp': lambda: check_index_exists(conn, 'idx_logs_email_timestamp'),
        'idx_logs_date_range': lambda: check_index_exists(conn, 'idx_logs_date_range'),
        'idx_logs_sync_covering': lambda: check_index_exists(conn, 'idx_logs_sync_covering'),
        'idx_sessions_active': lambda: check_index_exists(conn, 'idx_sessions_active'),
    }
    
    passed = 0
    total = len(checks)
    
    for check_name, check_func in checks.items():
        try:
            result = check_func()
            if result:
                print(f"   ‚úÖ {check_name}")
                passed += 1
            else:
                print(f"   ‚ùå {check_name}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  {check_name}: {e}")
    
    print(f"\n   –ü—Ä–æ–π–¥–µ–Ω–æ –ø—Ä–æ–≤–µ—Ä–æ–∫: {passed}/{total}")
    return passed == total

def check_index_exists(conn, index_name):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞"""
    result = conn.execute(
        "SELECT name FROM sqlite_master WHERE type='index' AND name=?",
        (index_name,)
    ).fetchone()
    return result is not None

def benchmark_query(conn, query, name, params=()):
    """–ü—Ä–æ—Å—Ç–æ–π –±–µ–Ω—á–º–∞—Ä–∫ –∑–∞–ø—Ä–æ—Å–∞"""
    import time
    
    times = []
    for _ in range(5):
        start = time.time()
        conn.execute(query, params).fetchall()
        elapsed = (time.time() - start) * 1000  # ms
        times.append(elapsed)
    
    avg = sum(times) / len(times)
    return avg

def run_benchmarks(conn, stats_before):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏"""
    print("\n‚ö° –ë–µ–Ω—á–º–∞—Ä–∫–∏ (—Å—Ä–µ–¥–Ω–µ–µ –∑–∞ 5 –∑–∞–ø—É—Å–∫–æ–≤)...")
    
    benchmarks = []
    
    # Benchmark 1: Pending sync
    if stats_before['pending_sync'] > 0:
        query = "SELECT * FROM logs WHERE synced = 0 ORDER BY priority DESC LIMIT 100"
        time_ms = benchmark_query(conn, query, "Sync queue")
        benchmarks.append(("Sync queue (100 records)", time_ms))
    
    # Benchmark 2: Active sessions
    query = "SELECT * FROM sessions WHERE logout_time IS NULL"
    time_ms = benchmark_query(conn, query, "Active sessions")
    benchmarks.append(("Active sessions", time_ms))
    
    # Benchmark 3: User history (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ)
    if stats_before['logs_count'] > 0:
        query = "SELECT * FROM logs WHERE email = 'test@example.com' ORDER BY timestamp DESC LIMIT 50"
        time_ms = benchmark_query(conn, query, "User history")
        benchmarks.append(("User history", time_ms))
    
    for name, time_ms in benchmarks:
        print(f"   {name:30} {time_ms:>8.2f} ms")
    
    print()

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("="*60)
    print("Migration 005: Performance Optimization –¥–ª—è 200 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    print("="*60)
    print()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –ë–î
    if not DB_PATH.exists():
        print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {DB_PATH}")
        print("   –°–æ–∑–¥–∞–π—Ç–µ –ë–î –∑–∞–ø—É—Å–∫–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –º–∏–≥—Ä–∞—Ü–∏–π")
        return 1
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
    conn = sqlite3.connect(str(DB_PATH))
    conn.row_factory = sqlite3.Row
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –ª–∏ —É–∂–µ –º–∏–≥—Ä–∞—Ü–∏—è
        if check_migration_applied(conn):
            print("‚ÑπÔ∏è  –ú–∏–≥—Ä–∞—Ü–∏—è 005 —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞!")
            print()
            stats = get_db_stats(conn)
            print_stats(stats, "–¢–µ–∫—É—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
            return 0
        
        # –®–∞–≥ 1: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –î–û
        print("üìä –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –î–û –º–∏–≥—Ä–∞—Ü–∏–∏...")
        stats_before = get_db_stats(conn)
        print_stats(stats_before, "–î–æ –º–∏–≥—Ä–∞—Ü–∏–∏")
        
        # –®–∞–≥ 2: –ë—ç–∫–∞–ø
        backup_path = create_backup()
        print()
        
        # –®–∞–≥ 3: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏
        apply_migration(conn)
        print()
        
        # –®–∞–≥ 4: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ü–û–°–õ–ï
        print("üìä –°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ü–û–°–õ–ï –º–∏–≥—Ä–∞—Ü–∏–∏...")
        stats_after = get_db_stats(conn)
        print_stats(stats_after, "–ü–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏")
        
        # –®–∞–≥ 5: –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
        if not verify_migration(conn):
            print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –ø—Ä–æ—à–ª–∏")
            print(f"   –ë—ç–∫–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {backup_path}")
            return 1
        
        # –®–∞–≥ 6: –ë–µ–Ω—á–º–∞—Ä–∫–∏
        run_benchmarks(conn, stats_before)
        
        # –ò—Ç–æ–≥
        print("="*60)
        print("‚úÖ –ú–ò–ì–†–ê–¶–ò–Ø –£–°–ü–ï–®–ù–û –ü–†–ò–ú–ï–ù–ï–ù–ê!")
        print("="*60)
        print()
        print("–ò–∑–º–µ–Ω–µ–Ω–∏—è:")
        print(f"  ‚Ä¢ Journal mode: {stats_before['journal_mode']} ‚Üí {stats_after['journal_mode']}")
        print(f"  ‚Ä¢ –ò–Ω–¥–µ–∫—Å–æ–≤: {stats_before['indexes_count']} ‚Üí {stats_after['indexes_count']}")
        print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä –ë–î: {stats_before['db_size_kb']:.1f} KB ‚Üí {stats_after['db_size_kb']:.1f} KB")
        print()
        print("–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
        print("  ‚úì WAL —Ä–µ–∂–∏–º –¥–ª—è concurrent access (200+ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)")
        print("  ‚úì 7 –Ω–æ–≤—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
        print("  ‚úì Covering index –¥–ª—è batch —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏")
        print("  ‚úì Partial indexes –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞")
        print()
        print(f"–ë—ç–∫–∞–ø: {backup_path}")
        print()
        print("–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("  1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É")
        print("  2. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
        print("  3. –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –§–∞–∑–µ 2 (Connection Pool)")
        print()
        
        return 0
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –º–∏–≥—Ä–∞—Ü–∏–∏: {e}")
        print(f"   –ë—ç–∫–∞–ø —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {backup_path if 'backup_path' in locals() else '–Ω–µ —Å–æ–∑–¥–∞–Ω'}")
        print("   –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ë–î –∏–∑ –±—ç–∫–∞–ø–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ")
        import traceback
        traceback.print_exc()
        return 1
    
    finally:
        conn.close()

if __name__ == '__main__':
    import sys
    sys.exit(main())
